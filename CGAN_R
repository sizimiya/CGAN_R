import os
import pandas as pd
import torch
import torchvision
from torch.utils.data import Dataset, DataLoader
from matplotlib import pyplot as plt
from tqdm import tqdm
from torch import nn
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np

image_size = [1, 63, 63]
latent_dim = 96
label_emb_dim = 127
batch_size = 63
save_dir = 'cgan_images'
os.makedirs(save_dir, exist_ok=True)
use_gpu = torch.cuda.is_available()

class Generator(nn.Module):
    def __init__(self, nz=100, ngf=64, nc=1):
        super(Generator, self).__init__()
        self.ngf = ngf #生成器特征图通道数量（卷积核数量/out_channel）
        self.nz = nz # z维度（噪声维度, in_channel）
        self.nc = nc  # or_data通道
        self.embedding = nn.Embedding(10, label_emb_dim)
        self.layer1 = nn.Sequential(
            nn.Linear(latent_dim+label_emb_dim, 100*5*5),
            torch.nn.BatchNorm1d(100*5*5, momentum=False),
            nn.ReLU()
        )
        self.model = nn.Sequential(
            # 输入特征：z(100维向量)，输出特征：512*4*4
            nn.ConvTranspose2d(in_channels=nz, out_channels=ngf*8, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(ngf*8),
            nn.ReLU(True),
            # 输入特征：512*4*4，输出特征：256*8*8
            nn.ConvTranspose2d(in_channels=ngf*8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # 输入特征：256*8*8，输出特征：128*16*16
            nn.ConvTranspose2d(in_channels=ngf*4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # 输入特征：128*16*16，输出特征：64*32*32
            nn.ConvTranspose2d(in_channels=ngf * 2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # 输入特征：64*32*32，输出特征：nc(1*64*64)
            nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False),
            nn.Tanh()
        )

    def forward(self, z, labels):
        label_embedding = self.embedding(labels)
        z = torch.cat([z, label_embedding], axis=-1)   #torch.cat是tensor的拼接函数
        z = self.layer1(z)

        output = z.reshape(batch_size, -1, 5, 5)
        image = self.model(output)


        return image


class Discriminator(nn.Module):

    def __init__(self, ndf=64, nc=1):
        super(Discriminator, self).__init__()

        self.embedding = nn.Embedding(10, label_emb_dim)
        self.ndf = ndf  #判别器特征图通道数量（卷积核数量/out_channel）
        self.nc = nc   # or_data通道
        self.model = nn.Sequential(
            #输入特征：nc*64*64, 输出特征：64*32*32
            nn.Conv2d(in_channels=nc, out_channels=ndf, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # 输入特征：64*32*32, 输出特征：128*16*16
            nn.Conv2d(in_channels=ndf, out_channels=ndf*2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ndf*2),
            nn.LeakyReLU(0.2, inplace=True),
            # 输入特征：128*16*16, 输出特征：256*8*8
            nn.Conv2d(in_channels=ndf*2, out_channels=ndf*4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # 输入特征：256*8*8, 输出特征：512*4*4
            nn.Conv2d(in_channels=ndf*4, out_channels=ndf*8, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # 输入特征：512*4*4, 输出特征：1*1*1
            nn.Conv2d(in_channels=ndf*8, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),
            nn.Sigmoid()
        )
        self.layer2 = nn.Sequential(
            nn.Linear(1*64*64, 2048),
            nn.ReLU(),
            nn.Linear(2048, 64*64),
            nn.ReLU()
        )

    def forward(self, image, labels):
        label_embedding = self.embedding(labels)
        image = image.view((batch_size, -1))
        image = torch.cat([image.reshape(image.shape[0], -1), label_embedding], axis=-1)
        image = self.layer2(image).reshape([batch_size, 1, 64, 64])
        prob = self.model(image)
        prob = prob.view(batch_size, )

        return prob


#Training
class CsvDataset(Dataset):
    def __init__(self):
        super(CsvDataset, self).__init__()
        self.feature_path = 'data_trans.csv'
        self.label_path = 'data_label_10.csv'
        feature_df_ = pd.read_csv(self.feature_path)
        label_df_ = pd.read_csv(self.label_path)
        assert feature_df_.columns.tolist()[1:] == label_df_[label_df_.columns[0]].tolist(), \
            'feature name does not match label name'
        self.feature = [feature_df_[i].tolist() for i in feature_df_.columns[1:]]
        self.label = label_df_[label_df_.columns[1]]
        assert len(self.feature) == len(self.label)
        self.length = len(self.feature)

    def __getitem__(self, index):
        x = self.feature[index]
        x = torch.Tensor(x)
        x = x.reshape(1, 63, 63)

        y = self.label[index]

        return x, y

    def __len__(self):
        return self.length

train_dataset = CsvDataset()
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)


generator = Generator()
discriminator = Discriminator()

g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)
d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)

loss_fn = nn.BCELoss()
labels_one = torch.ones(batch_size, 1)
labels_zero = torch.zeros(batch_size, 1)

if use_gpu:
    print("use gpu for training")
    generator = generator.cuda()
    discriminator = discriminator.cuda()
    loss_fn = loss_fn.cuda()
    labels_one = labels_one.to("cuda")
    labels_zero = labels_zero.to("cuda")


#or_data是真实数据， pred_data是生成数据
num_epoch = 100
for epoch in range(num_epoch):
    for i, data in enumerate(train_loader):
        (x, y) = data
        or_data = x
        labels = y
        # or_data, labels = data

        z = torch.randn(batch_size, latent_dim)

        if use_gpu:
            or_data = or_data.to("cuda")
            z = z.to("cuda")
            labels = labels.to('cuda')

        pred_data = generator(z, labels)
        g_optimizer.zero_grad()

        recons_loss = torch.abs(pred_data-or_data).mean()

        g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_data, labels), labels_one)

        g_loss.backward()
        g_optimizer.step()

        d_optimizer.zero_grad()

        real_loss = loss_fn(discriminator(or_data, labels), labels_one)
        fake_loss = loss_fn(discriminator(pred_data.detach(), labels), labels_zero)
        d_loss = (real_loss + fake_loss)

        d_loss.backward()
        d_optimizer.step()

        # 观察real_loss与fake_loss，同时下降同时达到最小值，并且差不多大，说明D已经稳定了


        if i % 50 == 0:
            print(f"step:{len(train_loader)*epoch+i}, recons_loss:{recons_loss.item()}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}")


        if i % 100 == 0:
            i = len(train_loader)*epoch
            for index, data in enumerate(pred_data):
                data_ts = data.cpu()
                data_ts = data_ts.reshape(4096, -1)
                data_np = data_ts.detach().numpy()
                df = pd.DataFrame(data_np)
                data_df = df
                data_df.to_csv(f'./pred/data{str(i)}.csv', index=None)
                i += 1
